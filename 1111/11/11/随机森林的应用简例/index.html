<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>随机森林的应用简例.md | 蓝湖畔淅淅沥沥的雨</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="说明 - 2022-05-05 本篇博客为本人原创, 原发布于CSDN, 在搭建个人博客后使用爬虫批量爬取并挂到个人博客, 出于一些技术原因博客未能完全还原到初始版本(而且我懒得修改), 在观看体验上会有一些瑕疵 ,若有需求会发布重制版总结性新博客。发布时间统一定为1111年11月11日。钦此。 用jupyter lab 做的 太多了懒得排版 ​ 123456789101112131415161">
<meta property="og:type" content="article">
<meta property="og:title" content="随机森林的应用简例.md">
<meta property="og:url" content="http://example.com/1111/11/11/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E5%BA%94%E7%94%A8%E7%AE%80%E4%BE%8B/index.html">
<meta property="og:site_name" content="蓝湖畔淅淅沥沥的雨">
<meta property="og:description" content="说明 - 2022-05-05 本篇博客为本人原创, 原发布于CSDN, 在搭建个人博客后使用爬虫批量爬取并挂到个人博客, 出于一些技术原因博客未能完全还原到初始版本(而且我懒得修改), 在观看体验上会有一些瑕疵 ,若有需求会发布重制版总结性新博客。发布时间统一定为1111年11月11日。钦此。 用jupyter lab 做的 太多了懒得排版 ​ 123456789101112131415161">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="1111-11-11T03:06:11.000Z">
<meta property="article:modified_time" content="2022-06-30T10:05:58.822Z">
<meta property="article:author" content="StarsWhisper">
<meta property="article:tag" content="OldBlog(Before20220505)">
<meta property="article:tag" content="随机森林">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="蓝湖畔淅淅沥沥的雨" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="/images/avatar.png">
    <h2 class="author">StarsWhisper</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>77</strong><br>文章</div></a>
      <a href="/categories"><div><strong>32</strong><br>分类</div></a>
      <a href="/tags"><div><strong>63</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
          <a href="/bridges" title="Bridges">
            <li>传送门</li>
          </a>
        
          <a href="/knightabout" title="About">
            <li>关于</li>
          </a>
        
          <a href="/announcement" title="Announcement">
            <li>公告</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main"><article id="post-随机森林的应用简例" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/1111/11/11/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E5%BA%94%E7%94%A8%E7%AE%80%E4%BE%8B/" class="article-date">
  <time class="post-time" datetime="1111-11-11T03:06:11.000Z" itemprop="datePublished">
    <span class="post-month">11月</span><br/>
    <span class="post-day">11</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      随机森林的应用简例.md
    </h1>
  

        <div>
          
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%99%E7%BB%83%E6%88%91%E6%83%B3%E5%AD%A6%E6%8C%82%E8%BE%B9%E8%BA%B2%E7%89%9B/">教练我想学挂边躲牛</a>,<a class="article-category-link" href="/categories/%E6%95%99%E7%BB%83%E6%88%91%E6%83%B3%E5%AD%A6%E6%8C%82%E8%BE%B9%E8%BA%B2%E7%89%9B/%E7%9E%8E%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">瞎学机器学习</a>
  </div>

          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="说明-2022-05-05"><a class="markdownIt-Anchor" href="#说明-2022-05-05"></a> 说明 - 2022-05-05</h2>
<p>本篇博客为本人原创, 原发布于CSDN, 在搭建个人博客后使用爬虫批量爬取并挂到个人博客, 出于一些技术原因博客未能完全还原到初始版本(而且我懒得修改), 在观看体验上会有一些瑕疵 ,若有需求会发布重制版总结性新博客。发布时间统一定为1111年11月11日。钦此。</p>
<p>用jupyter lab 做的 太多了懒得排版</p>
<p>​</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">df_t = pd.read_excel(<span class="string">r&#x27;D:\EdgeDownloadPlace\复赛数据集\train.xlsx&#x27;</span>,header=<span class="literal">None</span>)</span><br><span class="line">​</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">r&#x27;D:\EdgeDownloadPlace\复赛数据集\features.txt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    features = re.findall(<span class="string">&#x27;[0-9] (.*)\n&#x27;</span>, f.read())</span><br><span class="line">features.insert(<span class="number">0</span>,<span class="string">&#x27;uid&#x27;</span>)</span><br><span class="line">features.append(<span class="string">&#x27;target&#x27;</span>)</span><br><span class="line">df_t.columns = features</span><br><span class="line">​</span><br><span class="line">df_t = df_t.drop(columns = <span class="string">&#x27;uid&#x27;</span>)</span><br><span class="line">arr_t = df_t.values</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start_time = time.time()</span><br><span class="line">param_grid = &#123;<span class="string">&#x27;n_estimators&#x27;</span> : np.arange(<span class="number">1</span>,<span class="number">201</span>,<span class="number">40</span>)&#125;</span><br><span class="line">rfc = RandomForestClassifier(random_state = <span class="number">435681971</span></span><br><span class="line">                            ,criterion = <span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">gs = GridSearchCV(rfc, param_grid, cv=<span class="number">4</span>)</span><br><span class="line">gs.fit(arr_t[:,:-<span class="number">1</span>],arr_t[:,-<span class="number">1</span>])</span><br><span class="line">​</span><br><span class="line">peak_n_lst = [gs.best_score_, gs.best_params_]</span><br><span class="line">end_time = time.time()</span><br><span class="line">time_span = end_time - start_time</span><br><span class="line">peak_n_lst</span><br><span class="line">​</span><br><span class="line">[<span class="number">0.9373961218836566</span>, &#123;<span class="string">&#x27;n_estimators&#x27;</span>: <span class="number">161</span>&#125;]</span><br><span class="line">time_span</span><br><span class="line"><span class="number">107.33542943000793</span></span><br><span class="line">peak_n = peak_n_lst[<span class="number">1</span>][<span class="string">&#x27;n_estimators&#x27;</span>]</span><br><span class="line">start_time = time.time()</span><br><span class="line">param_grid = &#123;<span class="string">&#x27;n_estimators&#x27;</span> : np.arange(peak_n-<span class="number">20</span>,peak_n+<span class="number">20</span>)&#125;</span><br><span class="line">rfc = RandomForestClassifier(random_state = <span class="number">435681971</span></span><br><span class="line">                            ,criterion = <span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">gs = GridSearchCV(rfc, param_grid, cv=<span class="number">4</span>)</span><br><span class="line">gs.fit(arr_t[:,:-<span class="number">1</span>],arr_t[:,-<span class="number">1</span>])</span><br><span class="line">​</span><br><span class="line">peak_n_lst = [gs.best_score_, gs.best_params_]</span><br><span class="line">end_time = time.time()</span><br><span class="line">time_span = end_time - start_time</span><br><span class="line">peak_n = peak_n_lst[<span class="number">1</span>][<span class="string">&#x27;n_estimators&#x27;</span>]</span><br><span class="line">peak_n</span><br><span class="line"><span class="number">170</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">param_grid = &#123;<span class="string">&#x27;max_depth&#x27;</span> : np.arange(<span class="number">1</span>,<span class="number">561</span>//<span class="number">2</span>,<span class="number">30</span>)&#125;</span><br><span class="line">rfc = RandomForestClassifier(random_state = <span class="number">435681971</span></span><br><span class="line">                            ,n_estimators = peak_n</span><br><span class="line">                            ,criterion = <span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">gs = GridSearchCV(rfc, param_grid, cv=<span class="number">4</span>)</span><br><span class="line">gs.fit(arr_t[:,:-<span class="number">1</span>],arr_t[:,-<span class="number">1</span>])</span><br><span class="line">​</span><br><span class="line">peak_depth_lst = [gs.best_score_, gs.best_params_]</span><br><span class="line">end_time = time.time()</span><br><span class="line">time_span = end_time - start_time</span><br><span class="line">peak_depth_lst</span><br><span class="line">[<span class="number">0.9386426592797784</span>, &#123;<span class="string">&#x27;max_depth&#x27;</span>: <span class="number">31</span>&#125;]</span><br><span class="line">time_span</span><br><span class="line"><span class="number">407.307009935379</span></span><br><span class="line">peak_depth = peak_depth_lst[<span class="number">1</span>][<span class="string">&#x27;max_depth&#x27;</span>]</span><br><span class="line">peak_depth</span><br><span class="line"><span class="number">31</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">param_grid = &#123;<span class="string">&#x27;max_depth&#x27;</span> : np.arange(peak_depth-<span class="number">20</span>, peak_depth+<span class="number">30</span>)&#125;</span><br><span class="line">rfc = RandomForestClassifier(random_state = <span class="number">435681971</span></span><br><span class="line">                            ,n_estimators = peak_n</span><br><span class="line">                            ,criterion = <span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">gs = GridSearchCV(rfc, param_grid, cv=<span class="number">4</span>)</span><br><span class="line">gs.fit(arr_t[:,:-<span class="number">1</span>],arr_t[:,-<span class="number">1</span>])</span><br><span class="line">​</span><br><span class="line">peak_depth_lst = [gs.best_score_, gs.best_params_]</span><br><span class="line">end_time = time.time()</span><br><span class="line">time_span = end_time - start_time</span><br><span class="line">peak_depth_lst</span><br><span class="line">[<span class="number">0.9393351800554016</span>, &#123;<span class="string">&#x27;max_depth&#x27;</span>: <span class="number">14</span>&#125;]</span><br><span class="line">time_span/<span class="number">60</span></span><br><span class="line">​</span><br><span class="line"><span class="number">31.484332279364267</span></span><br><span class="line">peak_depth = peak_depth_lst[<span class="number">1</span>][<span class="string">&#x27;max_depth&#x27;</span>]</span><br><span class="line">peak_depth</span><br><span class="line"><span class="number">14</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">param_grid = &#123;<span class="string">&#x27;min_samples_split&#x27;</span> : np.arange(<span class="number">2</span>,<span class="number">125</span>,<span class="number">30</span>)&#125;</span><br><span class="line">rfc = RandomForestClassifier(random_state = <span class="number">435681971</span></span><br><span class="line">                            ,n_estimators = peak_n</span><br><span class="line">                            ,max_depth = peak_depth</span><br><span class="line">                            ,criterion = <span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">gs = GridSearchCV(rfc, param_grid, cv=<span class="number">4</span>)</span><br><span class="line">gs.fit(arr_t[:,:-<span class="number">1</span>],arr_t[:,-<span class="number">1</span>])</span><br><span class="line">​</span><br><span class="line">peak_depth_lst = [gs.best_score_, gs.best_params_]</span><br><span class="line">end_time = time.time()</span><br><span class="line">time_span = end_time - start_time</span><br><span class="line">time_span/<span class="number">60</span></span><br><span class="line"><span class="number">3.157407291730245</span></span><br><span class="line"><span class="comment">#peak_depth_lst 上面忘记换名字了</span></span><br><span class="line">peak_minss = peak_depth_lst[<span class="number">1</span>][<span class="string">&#x27;min_samples_split&#x27;</span>]</span><br><span class="line">peak_minss</span><br><span class="line"><span class="number">2</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">param_grid = &#123;<span class="string">&#x27;min_samples_split&#x27;</span> : np.arange(<span class="number">2</span>,<span class="number">30</span>)&#125;</span><br><span class="line">rfc = RandomForestClassifier(random_state = <span class="number">435681971</span></span><br><span class="line">                            ,n_estimators = peak_n</span><br><span class="line">                            ,max_depth = peak_depth</span><br><span class="line">                            ,criterion = <span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">gs = GridSearchCV(rfc, param_grid, cv=<span class="number">4</span>)</span><br><span class="line">gs.fit(arr_t[:,:-<span class="number">1</span>],arr_t[:,-<span class="number">1</span>])</span><br><span class="line">​</span><br><span class="line">peak_depth_lst = [gs.best_score_, gs.best_params_]</span><br><span class="line">end_time = time.time()</span><br><span class="line">time_span = end_time - start_time</span><br><span class="line">time_span</span><br><span class="line"><span class="number">1053.7646670341492</span></span><br><span class="line">peak_depth_lst</span><br><span class="line">[<span class="number">0.9393351800554016</span>, &#123;<span class="string">&#x27;min_samples_split&#x27;</span>: <span class="number">2</span>&#125;]</span><br><span class="line">peak_minss = peak_depth_lst[<span class="number">1</span>][<span class="string">&#x27;min_samples_split&#x27;</span>]</span><br><span class="line">peak_minss</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">peak_n = <span class="number">170</span></span><br><span class="line">peak_depth = <span class="number">14</span></span><br><span class="line">peak_minss = <span class="number">3</span></span><br><span class="line"><span class="comment">#rfc = RandomForestClassifier(random_state = 435681971</span></span><br><span class="line"><span class="comment">#                            ,n_estimators = peak_n</span></span><br><span class="line"><span class="comment">#                            ,max_depth = peak_depth</span></span><br><span class="line"><span class="comment">#                            ,min_samples_split = peak_minss</span></span><br><span class="line"><span class="comment">#                            ,oob_score = True)</span></span><br><span class="line"><span class="comment">#rfc.fit(arr_t[:,:-1],arr_t[:,-1])</span></span><br><span class="line"><span class="comment">#rfc.oob_score_</span></span><br><span class="line"><span class="comment">#plt.figure(figsize = [20,5])</span></span><br><span class="line">​</span><br><span class="line"><span class="comment">#score_lst=[]</span></span><br><span class="line"><span class="comment">#for i in range(30):</span></span><br><span class="line"><span class="comment">#    rfc = RandomForestClassifier(#random_state = 435681971</span></span><br><span class="line"><span class="comment">#                                n_estimators = peak_n</span></span><br><span class="line"><span class="comment">#                                ,max_depth = peak_depth</span></span><br><span class="line"><span class="comment">#                                ,min_samples_split = peak_minss</span></span><br><span class="line"><span class="comment">#                                ,oob_score = True)</span></span><br><span class="line"><span class="comment">#    rfc.fit(arr_t[:,:-1],arr_t[:,-1])</span></span><br><span class="line"><span class="comment">#    score_lst.append(rfc.oob_score_)</span></span><br><span class="line"><span class="comment">#plt.plot(range(1,31),score_lst)</span></span><br><span class="line">​</span><br><span class="line">score_lst=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">    rfc = RandomForestClassifier(<span class="comment">#random_state = 435681971</span></span><br><span class="line">                                n_estimators = peak_n</span><br><span class="line">                                ,max_depth = peak_depth</span><br><span class="line">                                ,min_samples_split = peak_minss</span><br><span class="line">                                ,oob_score = <span class="literal">True</span></span><br><span class="line">                                ,criterion = <span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">    rfc.fit(arr_t[:,:-<span class="number">1</span>],arr_t[:,-<span class="number">1</span>])</span><br><span class="line">    score_lst.append(rfc.oob_score_)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">31</span>),score_lst,color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">​</span><br><span class="line">plt.show()   </span><br><span class="line"></span><br><span class="line">plt.figure(figsize = [<span class="number">15</span>,<span class="number">6</span>])</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">31</span>),score_lst,color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    rfc = RandomForestClassifier(<span class="comment">#random_state = 435681971</span></span><br><span class="line">                                n_estimators = peak_n</span><br><span class="line">                                ,max_depth = peak_depth</span><br><span class="line">                                ,min_samples_split = peak_minss</span><br><span class="line">                                ,oob_score = <span class="literal">True</span></span><br><span class="line">                                ,criterion = <span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">    rfc.fit(arr_t[:,:-<span class="number">1</span>],arr_t[:,-<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> rfc.oob_score_ &gt; <span class="number">0.978</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">df_a = pd.read_excel(<span class="string">r&#x27;D:\EdgeDownloadPlace\复赛数据集\test.xlsx&#x27;</span>,header=<span class="literal">None</span>)</span><br><span class="line">​</span><br><span class="line">df_a.columns = features[:-<span class="number">1</span>]</span><br><span class="line">​</span><br><span class="line">df_a = df_a.drop(columns= <span class="string">&#x27;uid&#x27;</span>)</span><br><span class="line">df_a</span><br><span class="line">tBodyAcc-mean()-X	tBodyAcc-mean()-Y	tBodyAcc-mean()-Z	tBodyAcc-std()-X	tBodyAcc-std()-Y	tBodyAcc-std()-Z	tBodyAcc-mad()-X	tBodyAcc-mad()-Y	tBodyAcc-mad()-Z	tBodyAcc-<span class="built_in">max</span>()-X	...	fBodyBodyGyroJerkMag-meanFreq()	fBodyBodyGyroJerkMag-skewness()	fBodyBodyGyroJerkMag-kurtosis()	angle(tBodyAccMean,gravity)	angle(tBodyAccJerkMean),gravityMean)	angle(tBodyGyroMean,gravityMean)	angle(tBodyGyroJerkMean,gravityMean)	angle(X,gravityMean)	angle(Y,gravityMean)	angle(Z,gravityMean)</span><br><span class="line"><span class="number">0</span>	<span class="number">0.278</span>	-<span class="number">0.01640</span>	-<span class="number">0.1240</span>	-<span class="number">0.998</span>	-<span class="number">0.9750</span>	-<span class="number">0.960</span>	-<span class="number">0.999</span>	-<span class="number">0.9750</span>	-<span class="number">0.958</span>	-<span class="number">0.9430</span>	...	<span class="number">0.1580</span>	-<span class="number">0.5950</span>	-<span class="number">0.861</span>	<span class="number">0.0535</span>	-<span class="number">0.00743</span>	-<span class="number">0.733</span>	<span class="number">0.7040</span>	-<span class="number">0.845</span>	<span class="number">0.180</span>	-<span class="number">0.0543</span></span><br><span class="line"><span class="number">1</span>	<span class="number">0.281</span>	-<span class="number">0.00996</span>	-<span class="number">0.1060</span>	-<span class="number">0.995</span>	-<span class="number">0.9730</span>	-<span class="number">0.986</span>	-<span class="number">0.995</span>	-<span class="number">0.9740</span>	-<span class="number">0.986</span>	-<span class="number">0.9400</span>	...	<span class="number">0.2670</span>	<span class="number">0.3400</span>	<span class="number">0.140</span>	-<span class="number">0.0206</span>	-<span class="number">0.12800</span>	-<span class="number">0.483</span>	-<span class="number">0.0707</span>	-<span class="number">0.848</span>	<span class="number">0.190</span>	-<span class="number">0.0344</span></span><br><span class="line"><span class="number">2</span>	<span class="number">0.277</span>	-<span class="number">0.01470</span>	-<span class="number">0.1070</span>	-<span class="number">0.999</span>	-<span class="number">0.9910</span>	-<span class="number">0.993</span>	-<span class="number">0.999</span>	-<span class="number">0.9910</span>	-<span class="number">0.992</span>	-<span class="number">0.9430</span>	...	<span class="number">0.7400</span>	-<span class="number">0.5640</span>	-<span class="number">0.766</span>	<span class="number">0.1060</span>	-<span class="number">0.09030</span>	-<span class="number">0.132</span>	<span class="number">0.4990</span>	-<span class="number">0.850</span>	<span class="number">0.189</span>	-<span class="number">0.0351</span></span><br><span class="line"><span class="number">3</span>	<span class="number">0.279</span>	-<span class="number">0.02300</span>	-<span class="number">0.1220</span>	-<span class="number">0.997</span>	-<span class="number">0.9750</span>	-<span class="number">0.983</span>	-<span class="number">0.997</span>	-<span class="number">0.9730</span>	-<span class="number">0.984</span>	-<span class="number">0.9420</span>	...	<span class="number">0.6620</span>	-<span class="number">0.7820</span>	-<span class="number">0.954</span>	-<span class="number">0.1220</span>	-<span class="number">0.02910</span>	-<span class="number">0.013</span>	-<span class="number">0.0569</span>	-<span class="number">0.761</span>	<span class="number">0.263</span>	<span class="number">0.0242</span></span><br><span class="line"><span class="number">4</span>	<span class="number">0.280</span>	-<span class="number">0.01390</span>	-<span class="number">0.1060</span>	-<span class="number">0.998</span>	-<span class="number">0.9880</span>	-<span class="number">0.990</span>	-<span class="number">0.998</span>	-<span class="number">0.9880</span>	-<span class="number">0.992</span>	-<span class="number">0.9420</span>	...	<span class="number">0.4290</span>	-<span class="number">0.3290</span>	-<span class="number">0.597</span>	-<span class="number">0.0283</span>	<span class="number">0.09240</span>	-<span class="number">0.822</span>	<span class="number">0.3680</span>	-<span class="number">0.759</span>	<span class="number">0.264</span>	<span class="number">0.0297</span></span><br><span class="line">...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...</span><br><span class="line"><span class="number">3074</span>	<span class="number">0.231</span>	-<span class="number">0.04230</span>	-<span class="number">0.0899</span>	-<span class="number">0.309</span>	-<span class="number">0.0791</span>	-<span class="number">0.152</span>	-<span class="number">0.391</span>	-<span class="number">0.0870</span>	-<span class="number">0.257</span>	<span class="number">0.0562</span>	...	-<span class="number">0.0310</span>	-<span class="number">0.1390</span>	-<span class="number">0.589</span>	<span class="number">0.2730</span>	<span class="number">0.85600</span>	-<span class="number">0.962</span>	<span class="number">0.9530</span>	-<span class="number">0.657</span>	<span class="number">0.276</span>	<span class="number">0.1770</span></span><br><span class="line"><span class="number">3075</span>	<span class="number">0.357</span>	-<span class="number">0.04460</span>	-<span class="number">0.1300</span>	-<span class="number">0.314</span>	-<span class="number">0.0556</span>	-<span class="number">0.173</span>	-<span class="number">0.386</span>	-<span class="number">0.0575</span>	-<span class="number">0.217</span>	<span class="number">0.0262</span>	...	<span class="number">0.0168</span>	-<span class="number">0.1630</span>	-<span class="number">0.593</span>	-<span class="number">0.7110</span>	-<span class="number">0.06120</span>	-<span class="number">0.706</span>	<span class="number">0.0646</span>	-<span class="number">0.660</span>	<span class="number">0.274</span>	<span class="number">0.1760</span></span><br><span class="line"><span class="number">3076</span>	<span class="number">0.284</span>	-<span class="number">0.00796</span>	-<span class="number">0.1190</span>	-<span class="number">0.309</span>	-<span class="number">0.0804</span>	-<span class="number">0.211</span>	-<span class="number">0.369</span>	-<span class="number">0.0971</span>	-<span class="number">0.301</span>	-<span class="number">0.1170</span>	...	-<span class="number">0.1100</span>	<span class="number">0.0245</span>	-<span class="number">0.393</span>	-<span class="number">0.0761</span>	-<span class="number">0.23900</span>	<span class="number">0.960</span>	<span class="number">0.0866</span>	-<span class="number">0.657</span>	<span class="number">0.272</span>	<span class="number">0.1830</span></span><br><span class="line"><span class="number">3077</span>	<span class="number">0.207</span>	<span class="number">0.02460</span>	-<span class="number">0.1040</span>	-<span class="number">0.365</span>	-<span class="number">0.1690</span>	-<span class="number">0.216</span>	-<span class="number">0.449</span>	-<span class="number">0.1860</span>	-<span class="number">0.326</span>	-<span class="number">0.1760</span>	...	-<span class="number">0.2140</span>	-<span class="number">0.3520</span>	-<span class="number">0.734</span>	<span class="number">0.5350</span>	-<span class="number">0.25700</span>	<span class="number">0.927</span>	-<span class="number">0.0843</span>	-<span class="number">0.657</span>	<span class="number">0.267</span>	<span class="number">0.1880</span></span><br><span class="line"><span class="number">3078</span>	<span class="number">0.331</span>	-<span class="number">0.06400</span>	-<span class="number">0.1170</span>	-<span class="number">0.068</span>	<span class="number">0.1560</span>	-<span class="number">0.317</span>	-<span class="number">0.149</span>	<span class="number">0.0701</span>	-<span class="number">0.291</span>	<span class="number">0.4120</span>	...	-<span class="number">0.0214</span>	-<span class="number">0.0863</span>	-<span class="number">0.468</span>	-<span class="number">0.3510</span>	-<span class="number">0.33600</span>	<span class="number">0.967</span>	-<span class="number">0.7150</span>	-<span class="number">0.810</span>	<span class="number">0.185</span>	<span class="number">0.1210</span></span><br><span class="line"><span class="number">3079</span> rows × <span class="number">561</span> columns</span><br><span class="line"></span><br><span class="line">arr_a = df_a.values</span><br><span class="line">arr_a</span><br><span class="line">array([[ <span class="number">0.278</span>  , -<span class="number">0.0164</span> , -<span class="number">0.124</span>  , ..., -<span class="number">0.845</span>  ,  <span class="number">0.18</span>   , -<span class="number">0.0543</span> ],</span><br><span class="line">       [ <span class="number">0.281</span>  , -<span class="number">0.00996</span>, -<span class="number">0.106</span>  , ..., -<span class="number">0.848</span>  ,  <span class="number">0.19</span>   , -<span class="number">0.0344</span> ],</span><br><span class="line">       [ <span class="number">0.277</span>  , -<span class="number">0.0147</span> , -<span class="number">0.107</span>  , ..., -<span class="number">0.85</span>   ,  <span class="number">0.189</span>  , -<span class="number">0.0351</span> ],</span><br><span class="line">       ...,</span><br><span class="line">       [ <span class="number">0.284</span>  , -<span class="number">0.00796</span>, -<span class="number">0.119</span>  , ..., -<span class="number">0.657</span>  ,  <span class="number">0.272</span>  ,  <span class="number">0.183</span>  ],</span><br><span class="line">       [ <span class="number">0.207</span>  ,  <span class="number">0.0246</span> , -<span class="number">0.104</span>  , ..., -<span class="number">0.657</span>  ,  <span class="number">0.267</span>  ,  <span class="number">0.188</span>  ],</span><br><span class="line">       [ <span class="number">0.331</span>  , -<span class="number">0.064</span>  , -<span class="number">0.117</span>  , ..., -<span class="number">0.81</span>   ,  <span class="number">0.185</span>  ,  <span class="number">0.121</span>  ]])</span><br><span class="line">answer = rfc.predict(arr_a).astype(np.int8).tolist()</span><br><span class="line"><span class="built_in">len</span>(answer)</span><br><span class="line"><span class="number">3079</span></span><br><span class="line">answer_df = pd.DataFrame(answer)</span><br><span class="line">answer_df</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">0</span>	<span class="number">5</span></span><br><span class="line"><span class="number">1</span>	<span class="number">5</span></span><br><span class="line"><span class="number">2</span>	<span class="number">5</span></span><br><span class="line"><span class="number">3</span>	<span class="number">5</span></span><br><span class="line"><span class="number">4</span>	<span class="number">5</span></span><br><span class="line">...	...</span><br><span class="line"><span class="number">3074</span>	<span class="number">2</span></span><br><span class="line"><span class="number">3075</span>	<span class="number">2</span></span><br><span class="line"><span class="number">3076</span>	<span class="number">2</span></span><br><span class="line"><span class="number">3077</span>	<span class="number">2</span></span><br><span class="line"><span class="number">3078</span>	<span class="number">3</span></span><br><span class="line"><span class="number">3079</span> rows × <span class="number">1</span> columns</span><br><span class="line"></span><br><span class="line">answer_df.to_excel(<span class="string">r&#x27;D:\EdgeDownloadPlace\复赛数据集\ANS\20201104try.xlsx&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line">ok</span><br></pre></td></tr></table></figure>
<p>​</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/1111/11/11/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E5%BA%94%E7%94%A8%E7%AE%80%E4%BE%8B/" data-id="cl50x8cph00gaccj30kh1cm2j" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OldBlog-Before20220505/" rel="tag">OldBlog(Before20220505)</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/" rel="tag">随机森林</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/1111/11/11/%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2%EF%BC%88%E8%B2%8C%E4%BC%BC%EF%BC%8C%E4%B8%8D%E5%A4%AA%E6%B8%85%E6%A5%9A%E6%98%AF%E4%B8%8D%E6%98%AF%EF%BC%8C%E8%87%AA%E5%B7%B1%E6%91%B8%E7%B4%A2%E9%A2%98%E7%9A%84%E6%97%B6%E5%80%99%E7%8C%9C%E4%BA%86%E4%B8%80%E4%B8%AA%EF%BC%89%20L3-025%20%E9%82%A3%E5%B0%B1%E5%88%AB%E6%8B%85%E5%BF%83%E4%BA%86%20(30%20%E5%88%86)/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          记忆化搜索（貌似，不太清楚是不是，自己摸索题的时候猜了一个） L3-025 那就别担心了 (30 分).md
        
      </div>
    </a>
  
  
    <a href="/1111/11/11/%EF%BC%88%E5%BC%BA%E8%A1%8C%E7%AE%97%E6%B3%95%EF%BC%89%E5%AF%B92019%E7%82%B9%E7%BE%8E%E8%B5%9BD%E9%A2%98%E6%9E%81%E7%AB%AF%E5%8C%96%E7%9A%84%E7%AE%97%E6%B3%95%E6%8E%A2%E8%AE%A8%E3%80%81%E8%AE%BE%E8%AE%A1%E4%B8%8E%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E6%9C%AA%E5%AE%8C,%E4%BD%86%E5%8F%AF%E8%83%BD%E4%B9%9F%E5%88%B0%E6%AD%A4%E4%B8%BA%E6%AD%A2%EF%BC%89/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">（强行算法）对2019点美赛D题极端化的算法探讨、设计与遇到的问题（未完,但可能也到此为止）.md</div>
    </a>
  
</nav>

  
</article>



</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">蓝湖畔淅淅沥沥的雨</h1>
    <h2 class="blog-subtitle">All tragedy erased, I see only wonders...</h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
          <a href="/bridges" title="Bridges">
            <li>传送门</li>
          </a>
        
          <a href="/knightabout" title="About">
            <li>关于</li>
          </a>
        
          <a href="/announcement" title="Announcement">
            <li>公告</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="/images/avatar.png">
    <h2 class="author">StarsWhisper</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>77</strong><br>文章</div></a>
      <a href="/categories"><div><strong>32</strong><br>分类</div></a>
      <a href="/tags"><div><strong>63</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/Wldcmzy" target="_blank" title="Github">
          Github
        </a>
      
        <a class="hvr-bounce-in" href="https://blog.csdn.net/wldcmzy" target="_blank" title="CSDN">
          CSDN
        </a>
      
        <a class="hvr-bounce-in" href="https://space.bilibili.com/83743701" target="_blank" title="bilibili(无技术和学习内容)">
          bilibili(无技术和学习内容)
        </a>
      
    </div>

    <div class="friend-link">
      <h2>友情链接</h2>
      
        <a class="hvr-bounce-in" href="https://shanamaid.github.io/" target="_blank" title="夏娜主题作者的博客">
          夏娜主题作者的博客
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2021 - 2022 StarsWhisper<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
	  (但是魔改)
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/announcement" title="" class="menuItem">公告</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">归档</a>
          
            <a href="/knightabout" title="" class="menuItem">关于</a>
          
            <a href="/bridges" title="" class="menuItem">传送门</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>